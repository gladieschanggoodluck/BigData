# BigData

1. Execute distributed compuƟng frameworks using MapReduce and Spark
2. Demonstrate knowledge of applicaƟons for big data storage, retrieval, processing, and modeling
using Amazon AWS, Hive, and others from the Hadoop ecosystem
3. Implement PySpark for prevalent data science tasks, including data analysis and machine
learning
4. Execute an end-to-end predicƟve modeling project using a large dataset
